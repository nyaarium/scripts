#!/usr/bin/env node

import { spawn } from "node:child_process";
import { writeFileSync } from "node:fs";
import { resolve } from "node:path";
import { z } from "zod";

// Schema definitions for the GitHub PR data
const AuthorSchema = z.object({
	login: z.string(),
	name: z.string().nullable().optional(),
});

const MergeCommitSchema = z.object({
	oid: z.string(),
});

const CommitSchema = z.object({
	oid: z.string(),
	committedDate: z.string(),
	messageHeadline: z.string(),
	messageBody: z.string().nullable(),
	authors: z.array(AuthorSchema).optional(),
});

const CommentSchema = z.object({
	id: z.string(),
	author: AuthorSchema,
	body: z.string(),
	createdAt: z.string(),
	updatedAt: z.string().nullable().optional(),
});

const PRSchema = z.object({
	state: z.string(),
	author: AuthorSchema,
	title: z.string(),
	body: z.string().nullable(),
	comments: z.array(CommentSchema),
	mergeStateStatus: z.string(),
	mergedAt: z.string().nullable(),
	mergeCommit: MergeCommitSchema.nullable(),
	commits: z.array(CommitSchema),
});

function printUsage() {
	console.log("");
	console.log("Usage: fetch-github-pr [<repo>] <pr-id> [--fetch-files] [--output-path <output-path>]");
	console.log("");
	console.log("  repo: Repository in owner/repo format (ex: microsoft/vscode)");
	console.log("  pr-id: The pull request number (numeric)");
	console.log("  --output-path: Optional path to write JSON output");
	console.log(
		"  --fetch-files: Will fetch file details on commits. Outputs can be too large for AI, so make sure you look at the number of commits first before calling with this flag (ideally under 10 commits). You can alternatively use github-fetch-commit tool on individual commits",
	);
	console.log("");
}

function parseArgs() {
	const args = process.argv.slice(2);

	if (args.length < 1) {
		printUsage();
		process.exit(1);
	}

	let repo = undefined;
	let prId = undefined;
	let outputPath = undefined;
	let fetchFiles = false;

	// Parse arguments
	let i = 0;
	while (i < args.length) {
		const arg = args[i];

		if (arg === "--output-path") {
			// Handle --output-path flag
			if (i + 1 >= args.length) {
				console.error("Error: --output-path requires a value");
				printUsage();
				process.exit(1);
			}
			outputPath = args[i + 1];
			i += 2;
		} else if (arg === "--fetch-files") {
			// Handle --fetch-files flag
			fetchFiles = true;
			i++;
		} else if (arg.includes("/")) {
			// This looks like a repo
			if (repo !== undefined) {
				console.error("Error: Multiple repositories specified");
				printUsage();
				process.exit(1);
			}
			// Validate repo format (must have exactly one slash)
			const slashCount = (arg.match(/\//g) || []).length;
			if (slashCount !== 1) {
				console.error(
					"Error: Repository must be in owner/repo format with exactly one slash (ex: microsoft/vscode)",
				);
				printUsage();
				process.exit(1);
			}
			repo = arg;
			i++;
		} else if (/^\d+$/.test(arg)) {
			// This looks like a numeric PR ID
			if (prId !== undefined) {
				console.error("Error: Multiple PR IDs specified");
				printUsage();
				process.exit(1);
			}
			prId = arg;
			i++;
		} else {
			console.error(`Error: Unrecognized argument: ${arg}`);
			printUsage();
			process.exit(1);
		}
	}

	// Validate required arguments
	if (prId === undefined) {
		console.error("Error: PR ID is required");
		printUsage();
		process.exit(1);
	}

	return { repo, prId, outputPath, fetchFiles };
}

async function fetchPR(repo, prId, fetchFiles = false) {
	return new Promise((resolve, reject) => {
		const cmdArgs = [
			"pr",
			"view",
			prId,
			"--json",
			"state,author,title,body,comments,mergeStateStatus,mergedAt,mergeCommit,commits",
		];

		if (repo) {
			cmdArgs.splice(2, 0, "--repo", repo);
		}

		const child = spawn("gh", cmdArgs, {
			stdio: ["ignore", "pipe", "pipe"],
		});

		let stdout = "";
		let stderr = "";

		child.stdout.on("data", (data) => {
			stdout += data.toString();
		});

		child.stderr.on("data", (data) => {
			stderr += data.toString();
		});

		child.on("close", async (code) => {
			if (code === 0) {
				try {
					const rawData = JSON.parse(stdout);
					const validatedData = PRSchema.parse(rawData);

					// Fetch detailed commit information for each commit
					const detailedCommits = await Promise.all(
						validatedData.commits.map(async (commit) => {
							// Check for dependabot patterns in commit message
							const dependabotPatterns = [
								/^Bump .+ from .+ to .+$/i, // "Bump xxx from xxx to xxxx"
								/^Bump .+ group with .+$/i, // "Bump xxx group with xxx"
								/from .+\/dependabot\//i, // "from xxx/dependabot/"
							];

							const isDependabot = dependabotPatterns.some(
								(pattern) =>
									pattern.test(commit.messageHeadline) ||
									(commit.messageBody && pattern.test(commit.messageBody)),
							);

							let message = commit.messageBody
								? `${commit.messageHeadline}\n${commit.messageBody}`.trim()
								: commit.messageHeadline.trim();

							if (isDependabot) {
								message = commit.messageHeadline.trim();
							}

							const author = commit.authors
								.map((author) => author.name)
								.sort()
								.join(", ");

							if (fetchFiles) {
								try {
									const commitDetails = await fetchCommitDetails(repo, commit.oid);

									const files = commitDetails.files || [];
									const transformedFiles = files.map((file) => ({
										filename: file.filename,
										status: file.status,
										urlWeb: file.blob_url,
										urlRaw: file.raw_url,
										patch: file.patch || null,
									}));

									console.log(commit);

									return {
										id: commit.oid,
										date: commit.committedDate,
										author,
										message,
										files: transformedFiles,
									};
								} catch (error) {
									return {
										id: commit.oid,
										date: commit.committedDate,
										author,
										message: message + "\n\n[Error: File details could not be fetched]",
										files: [],
									};
								}
							} else {
								return {
									id: commit.oid,
									date: commit.committedDate,
									author,
									message,
								};
							}
						}),
					);

					const transformedData = {
						state: validatedData.state,
						author: validatedData.author.name,
						title: validatedData.title,
						body: validatedData.body,
						comments: validatedData.comments,
						mergeStateStatus: validatedData.mergeStateStatus,
						mergedAt: validatedData.mergedAt,
						mergeCommit: validatedData.mergeCommit?.oid || null,
						commits: detailedCommits,
					};

					resolve(transformedData);
				} catch (error) {
					reject(new Error(`Failed to parse GitHub CLI output: ${error}`));
				}
			} else {
				reject(new Error(`GitHub CLI failed with code ${code}: ${stderr}`));
			}
		});

		child.on("error", (error) => {
			reject(new Error(`Failed to execute GitHub CLI: ${error.message}`));
		});
	});
}

async function fetchCommitDetails(repo, commitHash) {
	return new Promise((resolve, reject) => {
		let apiArgs;
		if (repo) {
			apiArgs = ["api", `repos/${repo}/commits/${commitHash}`];
		} else {
			// Use current repo context
			apiArgs = ["api", "repos/:owner/:repo/commits/" + commitHash];
		}

		const child = spawn("gh", apiArgs, {
			stdio: ["ignore", "pipe", "pipe"],
		});

		let stdout = "";
		let stderr = "";

		child.stdout.on("data", (data) => {
			stdout += data.toString();
		});

		child.stderr.on("data", (data) => {
			stderr += data.toString();
		});

		child.on("close", (code) => {
			if (code === 0) {
				try {
					const commitData = JSON.parse(stdout);
					resolve(commitData);
				} catch (error) {
					reject(new Error(`Failed to parse commit API response: ${error}`));
				}
			} else {
				reject(new Error(`GitHub API failed with code ${code}: ${stderr}`));
			}
		});

		child.on("error", (error) => {
			reject(new Error(`Failed to execute GitHub API: ${error.message}`));
		});
	});
}

async function main() {
	try {
		const { repo, prId, outputPath, fetchFiles } = parseArgs();

		console.log(`Fetching PR ${prId}${repo ? ` from ${repo}` : ""}...`);
		if (fetchFiles) {
			console.log("File details will be fetched for each commit");
		}

		const prData = await fetchPR(repo, prId, fetchFiles);

		if (outputPath) {
			// Write to file and output path info
			const outputPathAbs = resolve(outputPath);
			writeFileSync(outputPathAbs, JSON.stringify(prData, null, 2));

			const outputInfo = {
				outputPath: outputPath,
				outputPathAbs: outputPathAbs,
			};
			console.log(JSON.stringify(outputInfo, null, 2));
		} else {
			// Output the transformed data as JSON
			console.log(JSON.stringify(prData, null, 2));
		}
	} catch (error) {
		console.error("Error:", error.message);
		process.exit(1);
	}
}

main();
